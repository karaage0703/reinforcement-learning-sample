{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbVXrmEsLXDt"
   },
   "source": [
    "# ML-Agents Open a UnityEnvironment\n",
    "<img src=\"https://github.com/Unity-Technologies/ml-agents/blob/release_18_docs/docs/images/image-banner.png?raw=true\" align=\"middle\" width=\"435\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "- https://github.com/Unity-Technologies/ml-agents/blob/release_18_docs/docs/Python-API.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNKTwHU3d2-l"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pzj7wgapAcDs"
   },
   "source": [
    "### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N8yfQqkbebQ5"
   },
   "outputs": [],
   "source": [
    "import mlagents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_u74YhSmW6gD"
   },
   "source": [
    "## Run the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  env.close()\n",
    "except:\n",
    "  pass\n",
    "\n",
    "\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "# This is a non-blocking call that only loads the environment.\n",
    "#env = UnityEnvironment(file_name=None, worker_id=run_id, seed=1, side_channels=[])\n",
    "env = UnityEnvironment(file_name=None)\n",
    "# Start interacting with the environment.\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Unity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1lIx3_l24OP"
   },
   "source": [
    "### Reset the environment\n",
    "To reset the environment, simply call `env.reset()`. This method takes no argument and returns nothing but will send a signal to the simulation to reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dhtl0mpeqxYi"
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1rwnVq2qyoO"
   },
   "source": [
    "### Behavior Specs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrD0rSv92T8A"
   },
   "source": [
    "#### Get the Behavior Specs from the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "a7KatdThq7OV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the behavior : 3DBall?team=0\n"
     ]
    }
   ],
   "source": [
    "# We will only consider the first Behavior\n",
    "behavior_name = list(env.behavior_specs)[0]\n",
    "print(f\"Name of the behavior : {behavior_name}\")\n",
    "spec = env.behavior_specs[behavior_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1L8DHADrAbe"
   },
   "source": [
    "#### Get the Observation Space from the Behavior Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PqDTV5mSrJF5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :  1\n"
     ]
    }
   ],
   "source": [
    "# Examine the number of observations per Agent\n",
    "print(\"Number of observations : \", len(spec.observation_specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVLN_wbG1G5-"
   },
   "source": [
    "#### Get the Action Space from the Behavior Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "M9zk1-az1L-G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 continuous actions\n"
     ]
    }
   ],
   "source": [
    "# Is the Action continuous or multi-discrete ?\n",
    "if spec.action_spec.continuous_size > 0:\n",
    "  print(f\"There are {spec.action_spec.continuous_size} continuous actions\")\n",
    "if spec.action_spec.is_discrete():\n",
    "  print(f\"There are {spec.action_spec.discrete_size} discrete actions\")\n",
    "\n",
    "\n",
    "# How many actions are possible ?\n",
    "#print(f\"There are {spec.action_size} action(s)\")\n",
    "\n",
    "# For discrete actions only : How many different options does each action has ?\n",
    "if spec.action_spec.discrete_size > 0:\n",
    "  for action, branch_size in enumerate(spec.action_spec.discrete_branches):\n",
    "    print(f\"Action number {action} has {branch_size} different options\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cX07SGw22Lm"
   },
   "source": [
    "### Stepping the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xO5p0s0prfsQ"
   },
   "source": [
    "#### Get the steps from the Environment\n",
    "You can do this with the `env.get_steps(behavior_name)` method. If there are multiple behaviors in the Environment, you can call this method with each of the behavior's names.\n",
    "_Note_ This will not move the simulation forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ePZtcHXUrjyf"
   },
   "outputs": [],
   "source": [
    "decision_steps, terminal_steps = env.get_steps(behavior_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-Oj3ix530mx"
   },
   "source": [
    "#### Set actions for each behavior\n",
    "You can set the actions for the Agents of a Behavior by calling `env.set_actions()` you will need to specify the behavior name and pass a tensor of dimension 2. The first dimension of the action must be equal to the number of Agents that requested a decision during the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KB-nxfbw337g"
   },
   "outputs": [],
   "source": [
    "env.set_actions(behavior_name, spec.action_spec.empty_action(len(decision_steps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQCybRs84cmq"
   },
   "source": [
    "#### Move the simulation forward\n",
    "Call `env.step()` to move the simulation forward. The simulation will progress until an Agent requestes a decision or terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nl3K40ZR4bh2"
   },
   "outputs": [],
   "source": [
    "env.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y60u21sys8kA"
   },
   "source": [
    "### Run the Environment for a few episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "a2uQUsoMtIUK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rewards for episode 0 is 1.2000000327825546\n",
      "Total rewards for episode 1 is 1.9000000432133675\n",
      "Total rewards for episode 2 is 2.200000047683716\n"
     ]
    }
   ],
   "source": [
    "for episode in range(3):\n",
    "  env.reset()\n",
    "  decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "  tracked_agent = -1 # -1 indicates not yet tracking\n",
    "  done = False # For the tracked_agent\n",
    "  episode_rewards = 0 # For the tracked_agent\n",
    "  while not done:\n",
    "    # Track the first agent we see if not tracking\n",
    "    # Note : len(decision_steps) = [number of agents that requested a decision]\n",
    "    if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "      tracked_agent = decision_steps.agent_id[0]\n",
    "\n",
    "    # Generate an action for all agents\n",
    "    action = spec.action_spec.random_action(len(decision_steps))\n",
    "\n",
    "    # Set the actions\n",
    "    env.set_actions(behavior_name, action)\n",
    "\n",
    "    # Move the simulation forward\n",
    "    env.step()\n",
    "\n",
    "    # Get the new simulation results\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    if tracked_agent in decision_steps: # The agent requested a decision\n",
    "      episode_rewards += decision_steps[tracked_agent].reward\n",
    "    if tracked_agent in terminal_steps: # The agent terminated its episode\n",
    "      episode_rewards += terminal_steps[tracked_agent].reward\n",
    "      done = True\n",
    "  print(f\"Total rewards for episode {episode} is {episode_rewards}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-3grXNEtJPa"
   },
   "source": [
    "### Close the Environment to free the port it is using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vdWG6_SqtNtv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed environment\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "print(\"Closed environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Colab-UnityEnvironment-1-Run.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
